{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: 이기창, 2019, 한국어 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from preprocess import get_tokenizer     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install preprocessing         # 설치 오류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install </home/aiffel-dj23/preprocess-2.0.0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델피처 생성\n",
    "\n",
    "corpus_frame = ''\n",
    "\n",
    "documents, tokenized_corpus = [], []\n",
    "tokenizer = get_tokenizer(\"mecab\")\n",
    "\n",
    "with open(courpus_frame, 'r', encoding='utf-8') as f:\n",
    "    for document in f:\n",
    "        tokens = list(set(tokenizer.morphs(document.strip())))\n",
    "        documents.append(document)\n",
    "        tokenized_corpus.append(token)\n",
    "dictionary = corpora.Dictionary(tokenized_corpus)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 학습 및 결과 확인\n",
    "\n",
    "from gensim.models import ldamulticore\n",
    "\n",
    "LDA =ldamulticore.LdaMulticore(corpus, id2word=dictionary), num_topic =30, workers=4)\n",
    "\n",
    "all_topics = LDA.get_document_topics(corpus, minimum_probability=0.5, \n",
    "                                     per_word_topics= False)\n",
    "\n",
    "for doc_idx, topic in enumerate(all_topics[:5]):\n",
    "    print(doc_idx, topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 평가 모듈 선언\n",
    "\n",
    "from models.sent_eval import LDAEvaluator\n",
    "model = LDAEvaluator(\"data/sentence-embeddings/lda/lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽별 문서 확인\n",
    "\n",
    "model.show_topic_docs(topic_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토픽별 단어 확인\n",
    "\n",
    "model.show_topic_words(topic_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 문서의 토픽 확인\n",
    "\n",
    "model.show_new_document_topic([\"너무 사랑스러운 영화\", \"인생을 말하는 영화\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: https://joyhong.tistory.com/138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel \n",
    "from gensim.models.callbacks import CoherenceMetric \n",
    "from gensim import corpora \n",
    "from gensim.models.callbacks import PerplexityMetric \n",
    "import logging \n",
    "import pickle \n",
    "from gensim.models.coherencemodel import CoherenceModel \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyLDAvis==3.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화를 위해 설치\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사만 추출한 csv 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    coherence_values = [] \n",
    "    model_list = []\n",
    "    # ditionary는 Gensim dictionary, corpus는 Gensim corpus\n",
    "    # text는 list of input texts, limit 는 max of topics\n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "def find_optimal_number_of_topics(dictionary, corpus, processed_data):\n",
    "    limit = 40;\n",
    "    start = 2;\n",
    "    step = 6;\n",
    "    \n",
    "    model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=processed_data, start=start, limit=limit, step=step)\n",
    "\n",
    "    x = range(start, limit, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # 명사만으로 구성된 파일 open \n",
    "    processed_data = [sent.strip().split(\",\") for sent in tqdm(open('./Desktop/project/data/test01.csv', 'r', encoding='utf-8').readlines())]\n",
    "\n",
    "    # 정수 인코딩과 빈도수 생성\n",
    "    dictionary = corpora.Dictionary(processed_data)\n",
    "\n",
    "    # 출현빈도가 적거나 자주 등장하는 단어는 제거\n",
    "    dictionary.filter_extremes(no_below=10, no_above=0.05)\n",
    "    corpus = [dictionary.doc2bow(text) for text in processed_data]\n",
    "    print('Number of unique tokens: %d' % len(dictionary))\n",
    "    print('Number of documents: %d' % len(corpus))\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "     # 최적의 토픽 수 찾기\n",
    "    find_optimal_number_of_topics(dictionary, corpus, processed_data)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    processed_data = [sent.strip().split(\",\") for sent in tqdm(open('./tokenized_data.csv', 'r', encoding='utf-8').readlines())]\n",
    "    # 정수 인코딩과 빈도수 생성\n",
    "    dictionary = corpora.Dictionary(processed_data)\n",
    "\n",
    "    # 출현빈도가 적거나 자주 등장하는 단어 제거\n",
    "    dictionary.filter_extremes(no_below=10, no_above=0.05)\n",
    "    corpus = [dictionary.doc2bow(text) for text in processed_data]\n",
    "    print('Number of unique tokens: %d' % len(dictionary))\n",
    "    print('Number of documents: %d' % len(corpus))\n",
    "    \n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # 최적의 토픽 수 찾기 => 14개로 나옴\n",
    "\n",
    "    # 최적의 토픽 수 찾기 = 14개 나옴\n",
    "    \n",
    "    perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "    coherence_logger = CoherenceMetric(corpus=corpus, coherence=\"u_mass\", logger='shell')\n",
    "\n",
    "    lda_model = LdaModel(corpus, id2word=dictionary, num_topics=14, passes=30, callbacks=[coherence_logger, perplexity_logger])\n",
    "\n",
    "    topics = lda_model.print_topics(num_words=5)\n",
    "\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "    \n",
    "    # Compute Coherence Score using c_v\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_data, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('\\nCoherence Score (c_v): ', coherence_lda)\n",
    "\n",
    "    # Compute Coherence Score using UMass\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_data, dictionary=dictionary, coherence=\"u_mass\")\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('\\nCoherence Score (u_mass): ', coherence_lda)\n",
    "   \n",
    "    # 저장  \n",
    "    pickle.dump(corpus, open('./data/lda/lda_corpus.pkl', 'wb'))\n",
    "    dictionary.save('./data/lda/lda_dictionary.gensim')\n",
    "    lda_model.save('./data/lda/lda_model.gensim')\n",
    "\n",
    "    # pyLDAvis html 저장\n",
    "    lda_visualization = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "    pyLDAvis.save_html(lda_visualization, './data/lda/독립유공자공적조서_lda.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(lda_visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과\n",
    "u_mass는 0에 가까울수록 완벽한 일관성을 가진다는 의미이고 c_v는 0과 1사이로 0.55 정도면 준수하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
